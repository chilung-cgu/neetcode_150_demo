# Word Ladder (å­—è©æ¥é¾)

## 1. ğŸ§ Problem Dissection (é‡æ¸…å•é¡Œ)

çµ¦å®šå…©å€‹å–®è© `beginWord` å’Œ `endWord`ï¼Œä»¥åŠä¸€å€‹å­—å…¸ `wordList`ã€‚
è«‹æ‰¾å‡ºå¾ `beginWord` è®Šæ›åˆ° `endWord` çš„ **æœ€çŸ­è½‰æ›åºåˆ—** çš„é•·åº¦ã€‚
è®Šæ›è¦å‰‡ï¼š
1.  æ¯æ¬¡åªèƒ½æ”¹è®Šä¸€å€‹å­—æ¯ã€‚
2.  è®Šæ›éç¨‹ä¸­çš„ä¸­é–“å–®è©å¿…é ˆéƒ½åœ¨ `wordList` ä¸­ã€‚

-   **Input**: `beginWord = "hit", endWord = "cog", wordList = ["hot","dot","dog","lot","log","cog"]`
-   **Output**: `5`
    -   Explanation: "hit" -> "hot" -> "dot" -> "dog" -> "cog" (5 words).
-   **Input**: `beginWord = "hit", endWord = "cog", wordList = ["hot","dot","dog","lot","log"]`
-   **Output**: `0`
    -   "cog" not in list.
-   **Constraints**:
    -   1 <= word length <= 10.
    -   1 <= wordList length <= 5000.
    -   All words same length.

---

## 2. ğŸ¢ Brute Force Approach (æš´åŠ›è§£)

é€™æ˜¯ä¸€å€‹æœ€çŸ­è·¯å¾‘å•é¡Œã€‚
å¦‚æœæŠŠå–®è©çœ‹ä½œç¯€é»ï¼Œå¦‚æœå…©å€‹å–®è©åªå·®ä¸€å€‹å­—æ¯å‰‡é€£é‚Šã€‚
æˆ‘å€‘è¦æ‰¾å¾ `beginWord` åˆ° `endWord` çš„æœ€çŸ­è·¯å¾‘ã€‚
BFS æ˜¯è§£æ±ºç„¡æ¬Šåœ–æœ€çŸ­è·¯å¾‘çš„æ¨™æº–ç®—æ³•ã€‚

å¦‚æœå°æ–¼æ¯å€‹å–®è©ï¼Œå˜—è©¦æ‰€æœ‰å¯èƒ½çš„ 26*L è®Šæ›ä¾†å°‹æ‰¾é„°å±…ï¼Œæ™‚é–“è¤‡é›œåº¦ç‚º $O(M \times L \times 26)$ï¼Œå…¶ä¸­ $M$ æ˜¯å–®è©æ•¸ï¼Œ$L$ æ˜¯å–®è©é•·åº¦ã€‚

---

## 3. ğŸ’¡ The "Aha!" Moment (å„ªåŒ–)

é€™æ˜¯æ¨™æº–çš„ **BFS**ã€‚
æŠ€å·§åœ¨æ–¼å¦‚ä½•é«˜æ•ˆåœ°æ‰¾åˆ°é„°å±…ã€‚

**Option 1: Pre-process Adjacency List**
-   å°æ–¼æ¯ä¸€å°å–®è©ï¼Œæª¢æŸ¥æ˜¯å¦åªå·® 1 å€‹å­—æ¯ã€‚$O(M^2 \times L)$.
-   å¦‚æœ $M$ å¾ˆå¤§ (5000)ï¼Œé€™å€‹å»ºåœ–éç¨‹æœƒå¤ªæ…¢ã€‚

**Option 2: Generate Neighbors via Wildcard Map**
-   å°æ–¼å–®è© "hot"ï¼Œæˆ‘å€‘å¯ä»¥ç”Ÿæˆæ¨¡å¼ "*ot", "h*t", "ho*"ã€‚
-   å»ºç«‹ä¸€å€‹ Map: `pattern -> list of words`ã€‚
-   ä¾‹å¦‚ `*ot -> [hot, dot, lot]`ã€‚
-   é€™æ¨£åœ¨ BFS æ™‚ï¼Œå°æ–¼ "hit"ï¼Œç”Ÿæˆ "*it", "h*t", "hi*"ï¼Œç„¶å¾Œç›´æ¥å¾ Map ä¸­æŸ¥æ‰¾é„°å±…ã€‚
-   **Time**: $O(M \times L^2)$ ç”¨æ–¼é è™•ç†ï¼Œ$O(M \times L)$ ç”¨æ–¼ BFS æŸ¥æ‰¾ã€‚

**Input Constraints Analysis**:
-   $M=5000, L=10$.
-   $M^2 \times L = 2.5 \times 10^8$ (Might TLE).
-   $M \times L^2 \times 26 = 5000 \times 100 \times 26 \approx 1.3 \times 10^7$ (Safe).
-   æ³¨æ„ï¼šä¹Ÿå¯ä»¥ä¸é è™•ç† Mapï¼Œè€Œæ˜¯åœ¨ BFS éç¨‹ä¸­å‹•æ…‹ç”Ÿæˆ `a-z` çš„è®Šæ›ä¸¦æª¢æŸ¥ `wordSet`ã€‚é€™ä¹Ÿæ˜¯ $O(M \times L \times 26)$ã€‚é€™å€‹æ–¹æ³•é€šå¸¸æ¯”è¼ƒçœç©ºé–“ä¸”ä¸éœ€è¦ç¶­è­·è¤‡é›œçš„ Mapã€‚

**Algorithm (Dynamic Neighbor Generation)**:
1.  å°‡ `wordList` æ”¾å…¥ `unordered_set` ä»¥ä¾¿ $O(1)$ æŸ¥æ‰¾ã€‚
2.  Queue åˆå§‹åŒ– `q.push(beginWord)`ã€‚
3.  Level-by-level BFSã€‚
4.  å°æ–¼ç•¶å‰å–®è©ï¼Œå˜—è©¦ä¿®æ”¹æ¯ä¸€å€‹ä½ç½®çš„å­—ç¬¦ (a-z)ã€‚
5.  å¦‚æœä¿®æ”¹å¾Œçš„å–®è©å­˜åœ¨æ–¼ Set ä¸­ï¼Œå‰‡åŠ å…¥ Queue ä¸¦å¾ Set ä¸­ç§»é™¤ï¼ˆé¿å…é‡è¤‡è¨ªå•ï¼‰ã€‚
6.  å¦‚æœé‡åˆ° `endWord`ï¼Œå›å‚³ç•¶å‰å±¤æ•¸ + 1ã€‚

---

## 4. ğŸ’» Implementation (ç¨‹å¼ç¢¼)

### Approach: BFS with Set

```cpp
#include <vector>
#include <string>
#include <unordered_set>
#include <queue>

using namespace std;

class Solution {
public:
    int ladderLength(string beginWord, string endWord, vector<string>& wordList) {
        unordered_set<string> wordSet(wordList.begin(), wordList.end());
        
        // If endWord is not in the list, impossible
        if (wordSet.find(endWord) == wordSet.end()) return 0;
        
        queue<string> q;
        q.push(beginWord);
        
        int level = 1;
        
        while (!q.empty()) {
            int size = q.size();
            for (int i = 0; i < size; i++) {
                string curr = q.front();
                q.pop();
                
                if (curr == endWord) return level;
                
                // Try changing each character
                // We modify 'curr' directly and restore it to save space
                for (int j = 0; j < curr.size(); j++) {
                    char originalChar = curr[j];
                    
                    for (char c = 'a'; c <= 'z'; c++) {
                        if (c == originalChar) continue;
                        
                        curr[j] = c;
                        
                        // If transformed word is in dictionary
                        if (wordSet.find(curr) != wordSet.end()) {
                            q.push(curr);
                            wordSet.erase(curr); // Mark as visited
                        }
                    }
                    
                    // Restore
                    curr[j] = originalChar;
                }
            }
            level++;
        }
        
        return 0;
    }
};
```

### Python Reference

```python
from collections import deque

class Solution:
    def ladderLength(self, beginWord: str, endWord: str, wordList: List[str]) -> int:
        if endWord not in wordList:
            return 0
            
        nei = collections.defaultdict(list)
        wordList.append(beginWord)
        for word in wordList:
            for j in range(len(word)):
                pattern = word[:j] + "*" + word[j+1:]
                nei[pattern].append(word)
                
        visit = set([beginWord])
        q = deque([beginWord])
        res = 1
        
        while q:
            for i in range(len(q)):
                word = q.popleft()
                if word == endWord:
                    return res
                for j in range(len(word)):
                    pattern = word[:j] + "*" + word[j+1:]
                    for neighbor in nei[pattern]:
                        if neighbor not in visit:
                            visit.add(neighbor)
                            q.append(neighbor)
            res += 1
            
        return 0
```

---

## 5. ğŸ“ Detailed Code Comments (è©³ç´°è¨»è§£)

```cpp
class Solution {
public:
    int ladderLength(string beginWord, string endWord, vector<string>& wordList) {
        // ä½¿ç”¨ Set ä»¥ä¾¿ O(1) æŸ¥æ‰¾å–®è©æ˜¯å¦å­˜åœ¨
        unordered_set<string> wordSet(wordList.begin(), wordList.end());
        
        // å¦‚æœç›®æ¨™å–®è©ä¸åœ¨å­—å…¸ä¸­ï¼Œæ°¸é ç„¡æ³•åˆ°é”
        if (wordSet.find(endWord) == wordSet.end()) return 0;
        
        queue<string> q;
        q.push(beginWord);
        
        // åˆå§‹é•·åº¦ç‚º 1 (åŒ…å« beginWord æœ¬èº«)
        int level = 1;
        
        while (!q.empty()) {
            int size = q.size(); // ç•¶å‰å±¤çš„ç¯€é»æ•¸
            
            for (int i = 0; i < size; i++) {
                string curr = q.front();
                q.pop();
                
                // æ‰¾åˆ°ç›®æ¨™
                if (curr == endWord) return level;
                
                // å˜—è©¦å°‡ç•¶å‰å–®è©çš„æ¯å€‹å­—ç¬¦æ›¿æ›æˆ 'a' åˆ° 'z'
                for (int j = 0; j < curr.size(); j++) {
                    char originalChar = curr[j];
                    
                    for (char c = 'a'; c <= 'z'; c++) {
                        // è·³éè‡ªå·±
                        if (c == originalChar) continue;
                        
                        curr[j] = c;
                        
                        // æª¢æŸ¥è®Šæ›å¾Œçš„å–®è©æ˜¯å¦åœ¨å­—å…¸ä¸­
                        if (wordSet.find(curr) != wordSet.end()) {
                            q.push(curr);
                            // é—œéµå„ªåŒ–ï¼šä¸€æ—¦è¨ªå•éï¼Œå°±å¾å­—å…¸ä¸­ç§»é™¤
                            // é€™ç›¸ç•¶æ–¼æ¨™è¨˜ç‚º visitedï¼Œé˜²æ­¢é‡è¤‡è¨ªå•å’Œæ­»å¾ªç’°
                            wordSet.erase(curr);
                        }
                    }
                    
                    // é‚„åŸå­—ç¬¦ï¼Œä»¥ä¾¿å˜—è©¦ä¸‹ä¸€å€‹ä½ç½®çš„è®Šæ›
                    curr[j] = originalChar;
                }
            }
            // æ¯éæ­·å®Œä¸€å±¤ï¼Œè·¯å¾‘é•·åº¦åŠ  1
            level++;
        }
        
        return 0; // ç„¡æ³•åˆ°é”
    }
};
```

---

## 6. ğŸ“Š Rigorous Complexity Analysis (è¤‡é›œåº¦åˆ†æ)

-   **Time Complexity**: $O(M \times L \times 26)$
    -   $M$: Number of words in list.
    -   $L$: Length of each word.
    -   Each word is processed at most once. For each word, we iterate $L$ positions and try 26 chars.
-   **Space Complexity**: $O(M \times L)$
    -   Queue and Set store words.
